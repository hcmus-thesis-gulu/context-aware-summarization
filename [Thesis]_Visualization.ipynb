{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# A. Prepare Environments"
      ],
      "metadata": {
        "id": "HCCzInfJC1cs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "j8VunZztbvCb",
        "outputId": "dc467e7c-6014-4d4f-be0b-21e824a94b6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Clone Codes"
      ],
      "metadata": {
        "id": "PUx75E_-C4ER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "%rm -rf eval\n",
        "!git clone https://github.com/hcmus-thesis-gulu/human-centric-evaluation.git eval\n",
        "%cd /content/eval\n",
        "%ls -sla"
      ],
      "metadata": {
        "id": "H8SmDVjMbvo1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aca54f7-3274-4307-fa2f-e0658e3c2649"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'eval'...\n",
            "remote: Enumerating objects: 297, done.\u001b[K\n",
            "remote: Counting objects: 100% (176/176), done.\u001b[K\n",
            "remote: Compressing objects: 100% (118/118), done.\u001b[K\n",
            "remote: Total 297 (delta 110), reused 121 (delta 58), pack-reused 121\u001b[K\n",
            "Receiving objects: 100% (297/297), 43.29 MiB | 25.03 MiB/s, done.\n",
            "Resolving deltas: 100% (170/170), done.\n",
            "/content/eval\n",
            "total 540\n",
            "  4 drwxr-xr-x 6 root root   4096 Jun 15 07:09  \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "  4 drwxr-xr-x 1 root root   4096 Jun 15 07:09  \u001b[01;34m..\u001b[0m/\n",
            "  4 drwxr-xr-x 4 root root   4096 Jun 15 07:09  \u001b[01;34mclassic\u001b[0m/\n",
            "  4 drwxr-xr-x 8 root root   4096 Jun 15 07:09  \u001b[01;34m.git\u001b[0m/\n",
            "  4 -rw-r--r-- 1 root root   3085 Jun 15 07:09  .gitignore\n",
            "  4 drwxr-xr-x 2 root root   4096 Jun 15 07:09  \u001b[01;34mhuman-centric\u001b[0m/\n",
            "  4 drwxr-xr-x 2 root root   4096 Jun 15 07:09  \u001b[01;34mpreprocess\u001b[0m/\n",
            "  4 -rw-r--r-- 1 root root     26 Jun 15 07:09  README.md\n",
            "  4 -rw-r--r-- 1 root root    759 Jun 15 07:09  requirements.txt\n",
            "504 -rw-r--r-- 1 root root 512807 Jun 15 07:09 '[Thesis]_Testbed.ipynb'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Required libraries"
      ],
      "metadata": {
        "id": "pTdAqdC2C7wv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/eval\n",
        "%pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Dsa-RXpQn7ws",
        "outputId": "63bdac87-9618-4f3f-e9cc-31546ada795d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/eval\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting altair==5.0.1 (from -r requirements.txt (line 1))\n",
            "  Downloading altair-5.0.1-py3-none-any.whl (471 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.5/471.5 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs==23.1.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (23.1.0)\n",
            "Collecting blinker==1.6.2 (from -r requirements.txt (line 3))\n",
            "  Downloading blinker-1.6.2-py3-none-any.whl (13 kB)\n",
            "Collecting cachetools==5.3.1 (from -r requirements.txt (line 4))\n",
            "  Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
            "Collecting certifi==2023.5.7 (from -r requirements.txt (line 5))\n",
            "  Downloading certifi-2023.5.7-py3-none-any.whl (156 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.0/157.0 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting charset-normalizer==3.1.0 (from -r requirements.txt (line 6))\n",
            "  Downloading charset_normalizer-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.3/199.3 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click==8.1.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (8.1.3)\n",
            "Collecting decorator==5.1.1 (from -r requirements.txt (line 8))\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting gitdb==4.0.10 (from -r requirements.txt (line 9))\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting GitPython==3.1.31 (from -r requirements.txt (line 10))\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna==3.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (3.4)\n",
            "Collecting importlib-metadata==6.6.0 (from -r requirements.txt (line 12))\n",
            "  Downloading importlib_metadata-6.6.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: Jinja2==3.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (3.1.2)\n",
            "Collecting jsonschema==4.17.3 (from -r requirements.txt (line 14))\n",
            "  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.4/90.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markdown-it-py==2.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (2.2.0)\n",
            "Collecting MarkupSafe==2.1.3 (from -r requirements.txt (line 16))\n",
            "  Downloading MarkupSafe-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Requirement already satisfied: mdurl==0.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (0.1.2)\n",
            "Collecting numpy==1.24.3 (from -r requirements.txt (line 18))\n",
            "  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging==23.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 19)) (23.1)\n",
            "Collecting pandas==2.0.2 (from -r requirements.txt (line 20))\n",
            "  Downloading pandas-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow==9.5.0 (from -r requirements.txt (line 21))\n",
            "  Downloading Pillow-9.5.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf==4.23.2 (from -r requirements.txt (line 22))\n",
            "  Downloading protobuf-4.23.2-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyarrow==12.0.0 (from -r requirements.txt (line 23))\n",
            "  Downloading pyarrow-12.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.9/38.9 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck==0.8.1b0 (from -r requirements.txt (line 24))\n",
            "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pygments==2.15.1 (from -r requirements.txt (line 25))\n",
            "  Downloading Pygments-2.15.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pympler==1.0.1 (from -r requirements.txt (line 26))\n",
            "  Downloading Pympler-1.0.1-py3-none-any.whl (164 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.8/164.8 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyrsistent==0.19.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (0.19.3)\n",
            "Requirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (2.8.2)\n",
            "Collecting pytz==2023.3 (from -r requirements.txt (line 29))\n",
            "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.3/502.3 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz-deprecation-shim==0.1.0.post0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 30)) (0.1.0.post0)\n",
            "Collecting requests==2.31.0 (from -r requirements.txt (line 31))\n",
            "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rich==13.4.1 (from -r requirements.txt (line 32))\n",
            "  Downloading rich-13.4.1-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six==1.16.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 33)) (1.16.0)\n",
            "Collecting smmap==5.0.0 (from -r requirements.txt (line 34))\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Collecting streamlit==1.23.1 (from -r requirements.txt (line 35))\n",
            "  Downloading streamlit-1.23.1-py2.py3-none-any.whl (8.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity==8.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 36)) (8.2.2)\n",
            "Requirement already satisfied: toml==0.10.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 37)) (0.10.2)\n",
            "Requirement already satisfied: toolz==0.12.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 38)) (0.12.0)\n",
            "Collecting tornado==6.3.2 (from -r requirements.txt (line 39))\n",
            "  Downloading tornado-6.3.2-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (426 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.9/426.9 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing_extensions==4.6.3 (from -r requirements.txt (line 40))\n",
            "  Downloading typing_extensions-4.6.3-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: tzdata==2023.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 41)) (2023.3)\n",
            "Requirement already satisfied: tzlocal==4.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 42)) (4.3)\n",
            "Collecting urllib3==2.0.2 (from -r requirements.txt (line 43))\n",
            "  Downloading urllib3-2.0.2-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.2/123.2 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting validators==0.20.0 (from -r requirements.txt (line 44))\n",
            "  Downloading validators-0.20.0.tar.gz (30 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: zipp==3.15.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 45)) (3.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 46)) (1.10.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 47)) (3.8.0)\n",
            "Collecting watchdog (from streamlit==1.23.1->-r requirements.txt (line 35))\n",
            "  Downloading watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: validators\n",
            "  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19579 sha256=149d553bfdea779c810f30164661fe80d21d3400b654774c57a5336281bb3de8\n",
            "  Stored in directory: /root/.cache/pip/wheels/f2/ed/dd/d3a556ad245ef9dc570c6bcd2f22886d17b0b408dd3bbb9ac3\n",
            "Successfully built validators\n",
            "Installing collected packages: pytz, watchdog, urllib3, typing_extensions, tornado, smmap, Pympler, Pygments, protobuf, Pillow, numpy, MarkupSafe, jsonschema, importlib-metadata, decorator, charset-normalizer, certifi, cachetools, blinker, validators, rich, requests, pyarrow, pandas, gitdb, pydeck, GitPython, altair, streamlit\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2022.7.1\n",
            "    Uninstalling pytz-2022.7.1:\n",
            "      Successfully uninstalled pytz-2022.7.1\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.15\n",
            "    Uninstalling urllib3-1.26.15:\n",
            "      Successfully uninstalled urllib3-1.26.15\n",
            "  Attempting uninstall: typing_extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: tornado\n",
            "    Found existing installation: tornado 6.3.1\n",
            "    Uninstalling tornado-6.3.1:\n",
            "      Successfully uninstalled tornado-6.3.1\n",
            "  Attempting uninstall: Pygments\n",
            "    Found existing installation: Pygments 2.14.0\n",
            "    Uninstalling Pygments-2.14.0:\n",
            "      Successfully uninstalled Pygments-2.14.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 8.4.0\n",
            "    Uninstalling Pillow-8.4.0:\n",
            "      Successfully uninstalled Pillow-8.4.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.1.2\n",
            "    Uninstalling MarkupSafe-2.1.2:\n",
            "      Successfully uninstalled MarkupSafe-2.1.2\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.3.3\n",
            "    Uninstalling jsonschema-4.3.3:\n",
            "      Successfully uninstalled jsonschema-4.3.3\n",
            "  Attempting uninstall: decorator\n",
            "    Found existing installation: decorator 4.4.2\n",
            "    Uninstalling decorator-4.4.2:\n",
            "      Successfully uninstalled decorator-4.4.2\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 2.0.12\n",
            "    Uninstalling charset-normalizer-2.0.12:\n",
            "      Successfully uninstalled charset-normalizer-2.0.12\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2022.12.7\n",
            "    Uninstalling certifi-2022.12.7:\n",
            "      Successfully uninstalled certifi-2022.12.7\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 5.3.0\n",
            "    Uninstalling cachetools-5.3.0:\n",
            "      Successfully uninstalled cachetools-5.3.0\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.3.4\n",
            "    Uninstalling rich-13.3.4:\n",
            "      Successfully uninstalled rich-13.3.4\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.27.1\n",
            "    Uninstalling requests-2.27.1:\n",
            "      Successfully uninstalled requests-2.27.1\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 9.0.0\n",
            "    Uninstalling pyarrow-9.0.0:\n",
            "      Successfully uninstalled pyarrow-9.0.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "  Attempting uninstall: altair\n",
            "    Found existing installation: altair 4.2.2\n",
            "    Uninstalling altair-4.2.2:\n",
            "      Successfully uninstalled altair-4.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 2.0.2 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.27.1, but you have requests 2.31.0 which is incompatible.\n",
            "google-colab 1.0.0 requires tornado==6.3.1, but you have tornado 6.3.2 which is incompatible.\n",
            "moviepy 1.0.3 requires decorator<5.0,>=4.0.2, but you have decorator 5.1.1 which is incompatible.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.3 which is incompatible.\n",
            "pandas-gbq 0.17.9 requires pyarrow<10.0dev,>=3.0.0, but you have pyarrow 12.0.0 which is incompatible.\n",
            "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed GitPython-3.1.31 MarkupSafe-2.1.3 Pillow-9.5.0 Pygments-2.15.1 Pympler-1.0.1 altair-5.0.1 blinker-1.6.2 cachetools-5.3.1 certifi-2023.5.7 charset-normalizer-3.1.0 decorator-5.1.1 gitdb-4.0.10 importlib-metadata-6.6.0 jsonschema-4.17.3 numpy-1.24.3 pandas-2.0.2 protobuf-4.23.2 pyarrow-12.0.0 pydeck-0.8.1b0 pytz-2023.3 requests-2.31.0 rich-13.4.1 smmap-5.0.0 streamlit-1.23.1 tornado-6.3.2 typing_extensions-4.6.3 urllib3-2.0.2 validators-0.20.0 watchdog-3.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "certifi",
                  "decorator",
                  "numpy",
                  "pygments",
                  "tornado"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# B. Segmentations Exploration"
      ],
      "metadata": {
        "id": "0IqQnx-2CbVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "ArXpENOGn927"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Explore numbers"
      ],
      "metadata": {
        "id": "w9rIu506Chr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = h5py.File('/content/eval/classic/data/eccv16_dataset_summe_google_pool5.h5')\n",
        "print(data.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzXGV66opEYa",
        "outputId": "55e38690-13e1-420a-b2ca-42dfce42ddb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<KeysViewHDF5 ['video_1', 'video_10', 'video_11', 'video_12', 'video_13', 'video_14', 'video_15', 'video_16', 'video_17', 'video_18', 'video_19', 'video_2', 'video_20', 'video_21', 'video_22', 'video_23', 'video_24', 'video_25', 'video_3', 'video_4', 'video_5', 'video_6', 'video_7', 'video_8', 'video_9']>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['video_1'].keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtLsPc9EoRSz",
        "outputId": "22f2db2c-1b72-4edc-bb07-4c4b52b237ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KeysViewHDF5 ['change_points', 'features', 'gtscore', 'gtsummary', 'n_frame_per_seg', 'n_frames', 'n_steps', 'picks', 'user_summary', 'video_name']>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(data['video_1/change_points'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYaDoZjYo5tF",
        "outputId": "da17d63a-37d0-422a-dad4-92acad07b333"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,  244],\n",
              "       [ 245,  473],\n",
              "       [ 474,  827],\n",
              "       [ 828, 1081],\n",
              "       [1082, 1233],\n",
              "       [1234, 1438],\n",
              "       [1439, 1530],\n",
              "       [1531, 1642],\n",
              "       [1643, 1796],\n",
              "       [1797, 1973],\n",
              "       [1974, 1998],\n",
              "       [1999, 2110],\n",
              "       [2111, 2403],\n",
              "       [2404, 2539],\n",
              "       [2540, 2664],\n",
              "       [2665, 2908],\n",
              "       [2909, 3160],\n",
              "       [3161, 3370],\n",
              "       [3371, 3521],\n",
              "       [3522, 3649],\n",
              "       [3650, 3899],\n",
              "       [3900, 3940],\n",
              "       [3941, 3990],\n",
              "       [3991, 4034],\n",
              "       [4035, 4079],\n",
              "       [4080, 4138],\n",
              "       [4139, 4228],\n",
              "       [4229, 4285],\n",
              "       [4286, 4342],\n",
              "       [4343, 4493]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fps = np.array(data['video_1/n_frame_per_seg'])\n",
        "print(fps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4F6MGUyo-wN",
        "outputId": "1f7f8aaf-f28a-4213-bc11-190267e404d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[245 229 354 254 152 205  92 112 154 177  25 112 293 136 125 244 252 210\n",
            " 151 128 250  41  50  44  45  59  90  57  57 151]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(fps.sum(), np.array(data['video_1/n_frames']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOxbTGBXpI_p",
        "outputId": "3a1d753b-933d-47ae-85e2-bb370ba4f242"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4494 4494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(str(np.array(data[f'video_1/video_name']).astype(str)))\n",
        "print(np.array(data[f'video_1/video_name']).astype(str).item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rI3fEz1o4rDa",
        "outputId": "ba4b7529-9f71-473c-d928-96e07ec8d63c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Air_Force_One\n",
            "b'Air_Force_One'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Convert to json"
      ],
      "metadata": {
        "id": "39kLDrDCClzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "segmentations = {}"
      ],
      "metadata": {
        "id": "C45oVk5bpQKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for video_key in data:\n",
        "    video_name = np.array(data[f'{video_key}/video_name']).astype(str).item()\n",
        "    segmenation = {'video_name': video_name}\n",
        "    print(f'Processing video with key {video_key} which is {video_name}')\n",
        "\n",
        "    ends = np.array(data[f'{video_key}/change_points'])\n",
        "    frames = np.array(data[f'{video_key}/n_frame_per_seg'])\n",
        "\n",
        "    print(f'Total {len(ends)} segments!')\n",
        "\n",
        "    segmenation['segments'] = [\n",
        "        {\n",
        "            'idx': idx,\n",
        "            'start': int(segment[0][0]),\n",
        "            'end': int(segment[0][1]),\n",
        "            'num_frames': int(segment[1])\n",
        "        } for idx, segment in enumerate(zip(ends, frames))\n",
        "    ]\n",
        "\n",
        "    segmentations[video_key] = segmenation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7j1c52L-6ui",
        "outputId": "ebf2ade9-16e8-4851-9005-8a2d61226794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing video with key video_1 which is Air_Force_One\n",
            "Total 30 segments!\n",
            "Processing video with key video_10 which is Excavators river crossing\n",
            "Total 65 segments!\n",
            "Processing video with key video_11 which is Fire Domino\n",
            "Total 11 segments!\n",
            "Processing video with key video_12 which is Jumps\n",
            "Total 7 segments!\n",
            "Processing video with key video_13 which is Kids_playing_in_leaves\n",
            "Total 22 segments!\n",
            "Processing video with key video_14 which is Notre_Dame\n",
            "Total 31 segments!\n",
            "Processing video with key video_15 which is Paintball\n",
            "Total 41 segments!\n",
            "Processing video with key video_16 which is Playing_on_water_slide\n",
            "Total 21 segments!\n",
            "Processing video with key video_17 which is Saving dolphines\n",
            "Total 45 segments!\n",
            "Processing video with key video_18 which is Scuba\n",
            "Total 15 segments!\n",
            "Processing video with key video_19 which is St Maarten Landing\n",
            "Total 12 segments!\n",
            "Processing video with key video_2 which is Base jumping\n",
            "Total 32 segments!\n",
            "Processing video with key video_20 which is Statue of Liberty\n",
            "Total 26 segments!\n",
            "Processing video with key video_21 which is Uncut_Evening_Flight\n",
            "Total 65 segments!\n",
            "Processing video with key video_22 which is Valparaiso_Downhill\n",
            "Total 35 segments!\n",
            "Processing video with key video_23 which is car_over_camera\n",
            "Total 30 segments!\n",
            "Processing video with key video_24 which is paluma_jump\n",
            "Total 18 segments!\n",
            "Processing video with key video_25 which is playing_ball\n",
            "Total 21 segments!\n",
            "Processing video with key video_3 which is Bearpark_climbing\n",
            "Total 23 segments!\n",
            "Processing video with key video_4 which is Bike Polo\n",
            "Total 21 segments!\n",
            "Processing video with key video_5 which is Bus_in_Rock_Tunnel\n",
            "Total 35 segments!\n",
            "Processing video with key video_6 which is Car_railcrossing\n",
            "Total 34 segments!\n",
            "Processing video with key video_7 which is Cockpit_Landing\n",
            "Total 61 segments!\n",
            "Processing video with key video_8 which is Cooking\n",
            "Total 9 segments!\n",
            "Processing video with key video_9 which is Eiffel Tower\n",
            "Total 34 segments!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open('/content/segmentations.json', 'w', encoding='utf-8') as segment_file:\n",
        "    json.dump(segmentations, segment_file)"
      ],
      "metadata": {
        "id": "aXa4qIrEAZkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C. Visualize Results"
      ],
      "metadata": {
        "id": "R6MLwFBVCofj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/context\n",
        "%rm -rf \"/content/drive/MyDrive/HCMUS/Y4/Thesis/Codes/summe/clustering/dino/demo\"\n",
        "%mkdir \"/content/drive/MyDrive/HCMUS/Y4/Thesis/Codes/summe/clustering/dino/demo\""
      ],
      "metadata": {
        "id": "uNKVHnTOH2yK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Visualize latent space"
      ],
      "metadata": {
        "id": "f8zmHnKXCrZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run visualizer.py \\\n",
        "--video-folder data/videos \\\n",
        "--embedding-folder \"/content/drive/MyDrive/HCMUS/Y4/Thesis/Codes/summe/clustering/dino/embeddings\" \\\n",
        "--clustering-folder \"/content/drive/MyDrive/HCMUS/Y4/Thesis/Codes/summe/clustering/dino/clustering\" \\\n",
        "--demo-folder \"/content/drive/MyDrive/HCMUS/Y4/Thesis/Codes/summe/clustering/dino/demo\" \\\n",
        "--video-name Paintball \\\n",
        "--visual-type cluster \\\n",
        "--show-image \\\n",
        "--output-fps 4 \\\n",
        "--color-value label"
      ],
      "metadata": {
        "id": "VWyw92OZH6XZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Visualize temporal frames"
      ],
      "metadata": {
        "id": "TN5kkyjJCxuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run visualizer.py \\\n",
        "--video-folder data/videos \\\n",
        "--embedding-folder \"/content/drive/MyDrive/HCMUS/Y4/Thesis/Codes/summe/clustering/dino/embeddings\" \\\n",
        "--clustering-folder \"/content/drive/MyDrive/HCMUS/Y4/Thesis/Codes/summe/clustering/dino/clustering\" \\\n",
        "--demo-folder \"/content/drive/MyDrive/HCMUS/Y4/Thesis/Codes/summe/clustering/dino/demo\" \\\n",
        "--video-name Paintball \\\n",
        "--visual-type cluster \\\n",
        "--output-fps 4 \\\n",
        "--color-value label"
      ],
      "metadata": {
        "id": "hVfoMK1MH827"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}